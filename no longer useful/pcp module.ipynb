{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_annotations(csv_file):\n",
    "    \"\"\"Load and process the annotations CSV file.\"\"\"\n",
    "    # Read CSV file with specified column names\n",
    "    df = pd.read_csv(csv_file, header=None, \n",
    "                     names=['start_time', 'bar', 'beat', 'chord'])\n",
    "    \n",
    "    # Calculate end times by shifting start times\n",
    "    df['end_time'] = df['start_time'].shift(-1)\n",
    "    # For the last segment, we'll need to handle it separately\n",
    "    df = df.fillna(method='ffill')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcp_vectorise_segment(segment, sr, filename):\n",
    "    \"\"\"\n",
    "    Process audio segment to extract harmonic-based chroma features.\n",
    "    \n",
    "    Parameters:\n",
    "        segment: Audio time series\n",
    "        sr: Sampling rate\n",
    "        filename: Original filename for reporting\n",
    "    \n",
    "    Returns:\n",
    "        String: {filename}:{vector_str}\n",
    "    \"\"\"\n",
    "    n_fft = 512\n",
    "    try:\n",
    "        # Harmonic-percussive source separation\n",
    "        padded = librosa.util.fix_length(segment, size = n_fft)\n",
    "        y_harmonic, y_percussive = librosa.effects.hpss(segment, n_fft=n_fft)\n",
    "        \n",
    "        # Compute CQT-based chromagram from harmonic signal\n",
    "        chromagram = librosa.feature.chroma_cqt(\n",
    "            y=y_harmonic,\n",
    "            sr=sr,\n",
    "            #norm=None  # Keep the original magnitude\n",
    "        )\n",
    "        \n",
    "        # Reduce the chromagram to a single 12-dimensional vector using median\n",
    "        chroma_reduced = np.median(chromagram, axis=1)\n",
    "        \n",
    "        # Ensure we have a 12-dimensional vector\n",
    "        assert len(chroma_reduced) == 12, f\"Expected 12 dimensions, got {len(chroma_reduced)}\"\n",
    "        \n",
    "        # Create formatted string of the vector with 6 decimal places\n",
    "        vector_str = ','.join([f\"{x:.6f}\" for x in chroma_reduced])\n",
    "    \n",
    "        return f\"[{vector_str}]\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing segment {filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(chord: str) -> list[int]:\n",
    "    chord_list = ['Cmaj', 'Cmin', 'C#maj', 'C#min', 'Dmaj', 'Dmin', 'D#maj', 'D#min', \n",
    "              'Emaj', 'Emin', 'Fmaj', 'Fmin', 'F#maj', 'F#min', 'Gmaj', 'Gmin', \n",
    "              'G#maj', 'G#min', 'Amaj', 'Amin', 'A#maj', 'A#min', 'Bmaj', 'Bmin']\n",
    "    encoding = [0] * 24\n",
    "    if chord in chord_list:\n",
    "        encoding[chord_list.index(chord)] = 1\n",
    "    else:\n",
    "        raise ValueError(f\"Chord '{chord}' not found in chord_list.\")\n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_audio_and_save_pcp(audio_file_name, dataset_location, annotations_df, output_dir, logging_level=0):\n",
    "    \"\"\"\n",
    "    Slice the audio file according to the annotations\n",
    "\n",
    "    Parameters:\n",
    "        audio_file_name: Name of audio file with extension. Do not put . or / before \n",
    "        dataset_location: Path till dataset directory\n",
    "        annotations_df: Pandas dataframe of csv file read\n",
    "        output_dir: Name of directory in which all vectors are to be stored\n",
    "        logging_level: Default 0\n",
    "            0 - None, 1 - Info level\n",
    "    \n",
    "    Returns:\n",
    "        None. Saves pcp in \n",
    "    \n",
    "    \"\"\"\n",
    "    audio_file_path = os.path.join(dataset_location, audio_file_name)\n",
    "    try:\n",
    "        if not os.path.exists(os.path.join(dataset_location,audio_file_name)):\n",
    "            raise FileNotFoundError(f\"Audio file not found: {audio_file_name}\")\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"Loading audio file: {audio_file_name}\")\n",
    "        y, sr = librosa.load(audio_file_path, sr=None)\n",
    "        print(f\"Audio loaded with sampling rate: {sr} Hz\")\n",
    "        \n",
    "        # Calculate samples per microsecond for precision checking\n",
    "        samples_per_microsecond = sr / 1_000_000\n",
    "        print(f\"Samples per microsecond: {samples_per_microsecond}\")\n",
    "        \n",
    "        with open(f'./{output_dir}/{audio_file_name}_pcpvectors.txt', 'w') as file:\n",
    "            # Process all rows except the last one since last file will be of 0 bytes\n",
    "            for idx, row in annotations_df.iloc[:-1].iterrows():\n",
    "                chord = row['chord'].strip().replace(\"'\", \"\").replace('\"', \"\") \n",
    "                if chord == 'N.C.': # Discard the lines that are corrupt in dataset\n",
    "                    continue\n",
    "\n",
    "                # Convert times to sample indices with high precision\n",
    "                start_idx = int(np.floor(row['start_time'] * sr))\n",
    "                end_idx = int(np.floor(row['end_time'] * sr))\n",
    "                \n",
    "                # Ensure we don't exceed array bounds\n",
    "                end_idx = min(end_idx, len(y))\n",
    "                segment = y[start_idx:end_idx] # Slicing\n",
    "                \n",
    "                # Create filename with new format: line_chord_start_end.mp3\n",
    "                filename = f\"{idx+1}_{chord}_{row['start_time']:.6f}_{row['end_time']:.6f}.mp3\"\n",
    "                \n",
    "                # Save the segment with original sampling rate\n",
    "                # output_path = os.path.join(output_dir, filename)\n",
    "                # sf.write(output_path, segment, sr)\n",
    "                \n",
    "                pcp_vector = pcp_vectorise_segment(segment, sr, filename)\n",
    "                one_hot_encoded_list = one_hot_encoder(chord)\n",
    "                file.write(str(one_hot_encoded_list)+ ','+ pcp_vector + '\\n')\n",
    "\n",
    "                if logging_level == 1:\n",
    "                # Print detailed timing information\n",
    "                    print(f\"Processed: {filename}\")\n",
    "                    print(f\"Segment info:\")\n",
    "                    print(f\"  Start time: {row['start_time']:.6f} seconds\")\n",
    "                    print(f\"  End time: {row['end_time']:.6f} seconds\")\n",
    "                    # segment_duration = len(segment) / sr\n",
    "                    # print(f\"  Duration: {segment_duration:.6f} seconds\")\n",
    "                    print(f\"  Samples: {len(segment)}\")\n",
    "\n",
    "        print(f\"Processed: {audio_file_name}\")      \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio: {str(e)}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshaj\\AppData\\Local\\Temp\\ipykernel_18812\\866735786.py:10: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n",
      "c:\\Users\\Akshaj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=899\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio file: 0001_mix.mp3\n",
      "Audio loaded with sampling rate: 44100 Hz\n",
      "Samples per microsecond: 0.0441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Akshaj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=450\n",
      "  warnings.warn(\n",
      "c:\\Users\\Akshaj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=225\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0001_mix.mp3\n"
     ]
    }
   ],
   "source": [
    "audio_file_name = '0001_mix.mp3'\n",
    "    dataset_location = \"./datasetmini/audio-mixes/\"\n",
    "    output_dir = 'modifications'\n",
    "    annotations_dir_loc = \"./datasetmini/annotations/\"\n",
    "    annotations_file_name = \"0001_beatinfo.csv\"\n",
    "\n",
    "    annotations_file = os.path.join(annotations_dir_loc, annotations_file_name)\n",
    "    annotations_df = load_annotations(annotations_file)\n",
    "    process_audio_and_save_pcp(audio_file_name, dataset_location, annotations_df, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
