{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 19:16:39.795416: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-29 19:16:39.966260: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-29 19:16:40.013730: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 19:16:40.325196: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-29 19:16:42.901786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def parse_file(content):\n",
    "    x_data=[]\n",
    "    y_data=[]\n",
    "    lines = [line.strip() for line in content.split('\\n') if line.strip()]\n",
    "    for line in lines:\n",
    "        # Remove any whitespace and split by '],['\n",
    "        arrays = line.replace(' ', '').strip('[]').split('],[')\n",
    "        \n",
    "        if len(arrays) == 2:\n",
    "            try:\n",
    "                # Parse integers for X\n",
    "                x_array = [int(x) for x in arrays[0].split(',')]\n",
    "                # Parse floats for Y\n",
    "                y_array = [float(x) for x in arrays[1].split(',')]\n",
    "                \n",
    "                # Only append if arrays have correct dimensions\n",
    "                if len(x_array) == 24 and len(y_array) == 12:\n",
    "                    x_data.append(x_array)\n",
    "                    y_data.append(y_array)\n",
    "            except (ValueError, IndexError):\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "                continue\n",
    "    return x_data, y_data\n",
    "\n",
    "def load_data_from_folder(folder):\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    data_files = [file for root, dirs, files in os.walk(folder) for file in files if file.endswith('.csv')]\n",
    "    for data_file in data_files:\n",
    "        with open(os.path.join(folder,data_file), 'r') as file:\n",
    "            content = file.read()\n",
    "            x,y = parse_file(content)\n",
    "            all_x += x\n",
    "            all_y += y\n",
    "    X = np.array(all_x, dtype=np.int32)\n",
    "    Y = np.array(all_y, dtype= np.float32)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ffnn_model():\n",
    "    \"\"\"\n",
    "    Creates a Feed-Forward Neural Network model for predicting \n",
    "    24 float values from 12 input values\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        InputLayer(shape=(12,)),\n",
    "        # Input layer\n",
    "        Dense(24, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Hidden layers\n",
    "        Dense(48, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(48, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(24, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(X_train, y_train, epochs=100, batch_size=32):\n",
    "    \"\"\"\n",
    "    Train the model with the provided data\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: numpy array of shape (n_samples, 12)\n",
    "    y_train: numpy array of shape (n_samples, 24)\n",
    "    \"\"\"\n",
    "    model = create_ffnn_model()\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model performance\n",
    "    \"\"\"\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\nTest Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Make some predictions\n",
    "    predictions = model.predict(X_test[:5])  # First 5 samples\n",
    "    print(\"\\nSample Predictions vs Actual Values:\")\n",
    "    for i in range(5):\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(\"Prediction:\", predictions[i].round(3))\n",
    "        print(\"Actual:\", y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 5692 samples from CSV files\n",
      "Input shape: (5692, 12)\n",
      "Output shape: (5692, 24)\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"pcpvectors\"\n",
    "# y,X for maintaining convention from this point onwards\n",
    "y,X = load_data_from_folder(data_folder) \n",
    "print(f\"\\nLoaded {len(X)} samples from CSV files\")\n",
    "print(f\"Input shape: {X.shape}\")\n",
    "print(f\"Output shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730209605.924587     860 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730209606.305230     860 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730209606.305352     860 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730209606.310670     860 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730209606.310750     860 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730209606.310792     860 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730209607.077666     860 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1730209607.077760     860 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-29 19:16:47.077774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1730209607.077840     860 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-29 19:16:47.078604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2255 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730209611.673713    2822 service.cc:146] XLA service 0x7f9ea0006be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1730209611.673777    2822 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 Ti, Compute Capability 7.5\n",
      "2024-10-29 19:16:51.764559: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-29 19:16:52.255360: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 44/114\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0444 - loss: 0.8293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730209614.758208    2822 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.1000 - loss: 0.7754 - val_accuracy: 0.1284 - val_loss: 0.5506\n",
      "Epoch 2/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3883 - loss: 0.4800 - val_accuracy: 0.3381 - val_loss: 0.2469\n",
      "Epoch 3/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4737 - loss: 0.2040 - val_accuracy: 0.5598 - val_loss: 0.1381\n",
      "Epoch 4/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5308 - loss: 0.1318 - val_accuracy: 0.5862 - val_loss: 0.1031\n",
      "Epoch 5/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5724 - loss: 0.1096 - val_accuracy: 0.6147 - val_loss: 0.0849\n",
      "Epoch 6/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6180 - loss: 0.0985 - val_accuracy: 0.6454 - val_loss: 0.0754\n",
      "Epoch 7/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6385 - loss: 0.0903 - val_accuracy: 0.6850 - val_loss: 0.0688\n",
      "Epoch 8/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6655 - loss: 0.0857 - val_accuracy: 0.7223 - val_loss: 0.0638\n",
      "Epoch 9/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.0809 - val_accuracy: 0.7684 - val_loss: 0.0597\n",
      "Epoch 10/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6979 - loss: 0.0770 - val_accuracy: 0.7739 - val_loss: 0.0568\n",
      "Epoch 11/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 0.0711 - val_accuracy: 0.8024 - val_loss: 0.0535\n",
      "Epoch 12/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7417 - loss: 0.0696 - val_accuracy: 0.7991 - val_loss: 0.0515\n",
      "Epoch 13/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7434 - loss: 0.0676 - val_accuracy: 0.8244 - val_loss: 0.0484\n",
      "Epoch 14/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7567 - loss: 0.0661 - val_accuracy: 0.8310 - val_loss: 0.0465\n",
      "Epoch 15/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7701 - loss: 0.0616 - val_accuracy: 0.8299 - val_loss: 0.0448\n",
      "Epoch 16/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7755 - loss: 0.0607 - val_accuracy: 0.8386 - val_loss: 0.0430\n",
      "Epoch 17/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7704 - loss: 0.0603 - val_accuracy: 0.8430 - val_loss: 0.0422\n",
      "Epoch 18/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7859 - loss: 0.0553 - val_accuracy: 0.8474 - val_loss: 0.0407\n",
      "Epoch 19/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7913 - loss: 0.0536 - val_accuracy: 0.8430 - val_loss: 0.0399\n",
      "Epoch 20/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8039 - loss: 0.0523 - val_accuracy: 0.8507 - val_loss: 0.0392\n",
      "Epoch 21/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7949 - loss: 0.0536 - val_accuracy: 0.8540 - val_loss: 0.0390\n",
      "Epoch 22/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8034 - loss: 0.0525 - val_accuracy: 0.8584 - val_loss: 0.0377\n",
      "Epoch 23/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8187 - loss: 0.0490 - val_accuracy: 0.8650 - val_loss: 0.0372\n",
      "Epoch 24/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8092 - loss: 0.0515 - val_accuracy: 0.8661 - val_loss: 0.0362\n",
      "Epoch 25/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8011 - loss: 0.0497 - val_accuracy: 0.8551 - val_loss: 0.0370\n",
      "Epoch 26/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.0496 - val_accuracy: 0.8716 - val_loss: 0.0358\n",
      "Epoch 27/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8228 - loss: 0.0472 - val_accuracy: 0.8749 - val_loss: 0.0351\n",
      "Epoch 28/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8206 - loss: 0.0474 - val_accuracy: 0.8705 - val_loss: 0.0347\n",
      "Epoch 29/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8250 - loss: 0.0453 - val_accuracy: 0.8760 - val_loss: 0.0340\n",
      "Epoch 30/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8402 - loss: 0.0443 - val_accuracy: 0.8683 - val_loss: 0.0342\n",
      "Epoch 31/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 0.0448 - val_accuracy: 0.8694 - val_loss: 0.0353\n",
      "Epoch 32/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8342 - loss: 0.0442 - val_accuracy: 0.8804 - val_loss: 0.0335\n",
      "Epoch 33/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8452 - loss: 0.0420 - val_accuracy: 0.8727 - val_loss: 0.0334\n",
      "Epoch 34/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8444 - loss: 0.0426 - val_accuracy: 0.8716 - val_loss: 0.0333\n",
      "Epoch 35/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8494 - loss: 0.0413 - val_accuracy: 0.8793 - val_loss: 0.0331\n",
      "Epoch 36/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8387 - loss: 0.0423 - val_accuracy: 0.8771 - val_loss: 0.0331\n",
      "Epoch 37/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8470 - loss: 0.0411 - val_accuracy: 0.8661 - val_loss: 0.0341\n",
      "Epoch 38/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8455 - loss: 0.0411 - val_accuracy: 0.8858 - val_loss: 0.0327\n",
      "Epoch 39/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8358 - loss: 0.0417 - val_accuracy: 0.8793 - val_loss: 0.0320\n",
      "Epoch 40/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8521 - loss: 0.0397 - val_accuracy: 0.8836 - val_loss: 0.0319\n",
      "Epoch 41/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8550 - loss: 0.0398 - val_accuracy: 0.8804 - val_loss: 0.0317\n",
      "Epoch 42/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.0414 - val_accuracy: 0.8804 - val_loss: 0.0328\n",
      "Epoch 43/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.0417 - val_accuracy: 0.8836 - val_loss: 0.0327\n",
      "Epoch 44/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8514 - loss: 0.0398 - val_accuracy: 0.8847 - val_loss: 0.0319\n",
      "Epoch 45/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8543 - loss: 0.0393 - val_accuracy: 0.8814 - val_loss: 0.0318\n",
      "Epoch 46/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8464 - loss: 0.0385 - val_accuracy: 0.8793 - val_loss: 0.0311\n",
      "Epoch 47/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8514 - loss: 0.0396 - val_accuracy: 0.8869 - val_loss: 0.0314\n",
      "Epoch 48/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8404 - loss: 0.0402 - val_accuracy: 0.8760 - val_loss: 0.0317\n",
      "Epoch 49/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8579 - loss: 0.0373 - val_accuracy: 0.8749 - val_loss: 0.0311\n",
      "Epoch 50/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8501 - loss: 0.0374 - val_accuracy: 0.8858 - val_loss: 0.0314\n",
      "Epoch 51/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8646 - loss: 0.0372 - val_accuracy: 0.8869 - val_loss: 0.0305\n",
      "Epoch 52/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 0.0377 - val_accuracy: 0.8836 - val_loss: 0.0313\n",
      "Epoch 53/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8469 - loss: 0.0382 - val_accuracy: 0.8836 - val_loss: 0.0317\n",
      "Epoch 54/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 0.0371 - val_accuracy: 0.8869 - val_loss: 0.0311\n",
      "Epoch 55/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8610 - loss: 0.0383 - val_accuracy: 0.8847 - val_loss: 0.0319\n",
      "Epoch 56/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 0.0377 - val_accuracy: 0.8825 - val_loss: 0.0316\n",
      "Epoch 57/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8536 - loss: 0.0369 - val_accuracy: 0.8869 - val_loss: 0.0303\n",
      "Epoch 58/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8732 - loss: 0.0350 - val_accuracy: 0.8924 - val_loss: 0.0295\n",
      "Epoch 59/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8650 - loss: 0.0346 - val_accuracy: 0.8858 - val_loss: 0.0311\n",
      "Epoch 60/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8701 - loss: 0.0357 - val_accuracy: 0.8836 - val_loss: 0.0296\n",
      "Epoch 61/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.0364 - val_accuracy: 0.8924 - val_loss: 0.0297\n",
      "Epoch 62/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8603 - loss: 0.0351 - val_accuracy: 0.8858 - val_loss: 0.0308\n",
      "Epoch 63/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8475 - loss: 0.0400 - val_accuracy: 0.8913 - val_loss: 0.0300\n",
      "Epoch 64/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8607 - loss: 0.0363 - val_accuracy: 0.8891 - val_loss: 0.0300\n",
      "Epoch 65/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8677 - loss: 0.0355 - val_accuracy: 0.8880 - val_loss: 0.0300\n",
      "Epoch 66/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8658 - loss: 0.0362 - val_accuracy: 0.8836 - val_loss: 0.0304\n",
      "Epoch 67/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8741 - loss: 0.0323 - val_accuracy: 0.8891 - val_loss: 0.0300\n",
      "Epoch 68/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8599 - loss: 0.0357 - val_accuracy: 0.8683 - val_loss: 0.0320\n",
      "Epoch 69/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8754 - loss: 0.0337 - val_accuracy: 0.8793 - val_loss: 0.0299\n",
      "Epoch 70/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8662 - loss: 0.0353 - val_accuracy: 0.8957 - val_loss: 0.0296\n",
      "Epoch 71/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.0364 - val_accuracy: 0.8902 - val_loss: 0.0298\n",
      "Epoch 72/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8697 - loss: 0.0344 - val_accuracy: 0.8935 - val_loss: 0.0302\n",
      "Epoch 73/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8682 - loss: 0.0355 - val_accuracy: 0.8847 - val_loss: 0.0302\n",
      "Epoch 74/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8810 - loss: 0.0348 - val_accuracy: 0.8902 - val_loss: 0.0294\n",
      "Epoch 75/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8723 - loss: 0.0332 - val_accuracy: 0.8804 - val_loss: 0.0299\n",
      "Epoch 76/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8704 - loss: 0.0337 - val_accuracy: 0.8913 - val_loss: 0.0298\n",
      "Epoch 77/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.0337 - val_accuracy: 0.8924 - val_loss: 0.0288\n",
      "Epoch 78/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8732 - loss: 0.0355 - val_accuracy: 0.8869 - val_loss: 0.0293\n",
      "Epoch 79/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8785 - loss: 0.0334 - val_accuracy: 0.8913 - val_loss: 0.0292\n",
      "Epoch 80/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8658 - loss: 0.0347 - val_accuracy: 0.8880 - val_loss: 0.0301\n",
      "Epoch 81/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8642 - loss: 0.0348 - val_accuracy: 0.8880 - val_loss: 0.0288\n",
      "Epoch 82/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8592 - loss: 0.0365 - val_accuracy: 0.8935 - val_loss: 0.0298\n",
      "Epoch 83/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8770 - loss: 0.0336 - val_accuracy: 0.8935 - val_loss: 0.0285\n",
      "Epoch 84/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 0.0369 - val_accuracy: 0.8924 - val_loss: 0.0283\n",
      "Epoch 85/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8835 - loss: 0.0332 - val_accuracy: 0.8880 - val_loss: 0.0289\n",
      "Epoch 86/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8691 - loss: 0.0350 - val_accuracy: 0.8935 - val_loss: 0.0277\n",
      "Epoch 87/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8622 - loss: 0.0349 - val_accuracy: 0.8913 - val_loss: 0.0292\n",
      "Epoch 88/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8726 - loss: 0.0328 - val_accuracy: 0.8869 - val_loss: 0.0288\n",
      "Epoch 89/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 0.0369 - val_accuracy: 0.8968 - val_loss: 0.0282\n",
      "Epoch 90/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8653 - loss: 0.0354 - val_accuracy: 0.8968 - val_loss: 0.0288\n",
      "Epoch 91/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.0335 - val_accuracy: 0.9045 - val_loss: 0.0281\n",
      "Epoch 92/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8743 - loss: 0.0327 - val_accuracy: 0.8935 - val_loss: 0.0285\n",
      "Epoch 93/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8683 - loss: 0.0343 - val_accuracy: 0.8825 - val_loss: 0.0295\n",
      "Epoch 94/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8863 - loss: 0.0317 - val_accuracy: 0.9012 - val_loss: 0.0277\n",
      "Epoch 95/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.0312 - val_accuracy: 0.8924 - val_loss: 0.0281\n",
      "Epoch 96/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8695 - loss: 0.0338 - val_accuracy: 0.8880 - val_loss: 0.0290\n",
      "Epoch 97/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8730 - loss: 0.0335 - val_accuracy: 0.8979 - val_loss: 0.0283\n",
      "Epoch 98/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8758 - loss: 0.0333 - val_accuracy: 0.9001 - val_loss: 0.0277\n",
      "Epoch 99/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8721 - loss: 0.0339 - val_accuracy: 0.8869 - val_loss: 0.0288\n",
      "Epoch 100/100\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8789 - loss: 0.0321 - val_accuracy: 0.8990 - val_loss: 0.0284\n"
     ]
    }
   ],
   "source": [
    "batch_size = min(32, int(np.sqrt(len(X))))\n",
    "print(batch_size)\n",
    "print(\"\\nTraining model...\")\n",
    "train_ratio = 0.8\n",
    "train_size = int(len(X) * train_ratio)\n",
    "\n",
    "# Shuffle and split\n",
    "indices = np.random.permutation(len(X))\n",
    "train_indices, test_indices = indices[:train_size], indices[train_size:]\n",
    "\n",
    "X_train, X_test = X[train_indices], X[test_indices]\n",
    "y_train, y_test = y[train_indices], y[test_indices]\n",
    "model, history = train_model(X_train,y_train, epochs=100, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n",
      "\n",
      "Test Loss: 0.0320\n",
      "Test Accuracy: 0.8709\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step\n",
      "\n",
      "Sample Predictions vs Actual Values:\n",
      "\n",
      "Sample 1:\n",
      "Prediction: [0.    0.    0.    0.    0.    0.    0.003 0.987 0.    0.    0.    0.\n",
      " 0.006 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      "Actual: [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Sample 2:\n",
      "Prediction: [0.002 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.959 0.021\n",
      " 0.001 0.    0.    0.002 0.    0.    0.    0.002 0.001 0.    0.    0.   ]\n",
      "Actual: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Sample 3:\n",
      "Prediction: [0.    0.    0.979 0.    0.    0.    0.    0.    0.    0.    0.    0.003\n",
      " 0.    0.    0.    0.    0.001 0.    0.    0.    0.    0.002 0.    0.   ]\n",
      "Actual: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Sample 4:\n",
      "Prediction: [0.    0.    0.    0.    0.    0.    0.    0.    0.002 0.001 0.    0.\n",
      " 0.    0.001 0.    0.    0.    0.    0.131 0.921 0.    0.    0.    0.   ]\n",
      "Actual: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "\n",
      "Sample 5:\n",
      "Prediction: [0.001 0.001 0.    0.    0.    0.001 0.002 0.    0.    0.    0.    0.\n",
      " 0.001 0.    0.053 0.915 0.001 0.    0.    0.003 0.002 0.    0.    0.   ]\n",
      "Actual: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating model...\")\n",
    "evaluate_model(model, X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['mae'], label='Training MAE')\n",
    "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    plt.title('Model MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# After training:\n",
    "plot_training_history(history) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.keras')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
